{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_index.json: 100%|██████████| 543/543 [00:00<00:00, 181kB/s]\n",
      "c:\\Users\\Katie\\anaconda3\\envs\\ldm\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Katie\\.cache\\huggingface\\hub\\models--runwayml--stable-diffusion-v1-5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Katie\\anaconda3\\envs\\ldm\\lib\\site-packages\\diffusers\\pipelines\\pipeline_utils.py:270: FutureWarning: You are loading the variant fp16 from runwayml/stable-diffusion-v1-5 via `revision='fp16'` even though you can load it via `variant=`fp16`. Loading model variants via `revision='fp16'` is deprecated and will be removed in diffusers v1. Please use `variant='fp16'` instead.\n",
      "  warnings.warn(\n",
      "vae\\diffusion_pytorch_model.safetensors not found\n",
      "scheduler/scheduler_config.json: 100%|██████████| 307/307 [00:00<00:00, 102kB/s]\n",
      "\n",
      "(…)ature_extractor/preprocessor_config.json: 100%|██████████| 342/342 [00:00<00:00, 81.8kB/s]\n",
      "text_encoder/config.json: 100%|██████████| 636/636 [00:00<00:00, 56.4kB/s]\n",
      "\n",
      "tokenizer/special_tokens_map.json: 100%|██████████| 472/472 [00:00<00:00, 77.4kB/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "tokenizer/merges.txt: 100%|██████████| 525k/525k [00:00<00:00, 3.46MB/s]\n",
      "tokenizer/tokenizer_config.json: 100%|██████████| 822/822 [00:00<00:00, 273kB/s]\n",
      "unet/config.json: 100%|██████████| 806/806 [00:00<00:00, 190kB/s]\n",
      "\n",
      "\n",
      "\n",
      "safety_checker/config.json: 100%|██████████| 4.70k/4.70k [00:00<00:00, 415kB/s]\n",
      "Fetching 15 files:  20%|██        | 3/15 [00:00<00:02,  5.28it/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vae/config.json: 100%|██████████| 609/609 [00:00<00:00, 200kB/s]\n",
      "\n",
      "\n",
      "\n",
      "tokenizer/vocab.json: 100%|██████████| 1.06M/1.06M [00:00<00:00, 1.66MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model.bin: 100%|██████████| 608M/608M [00:40<00:00, 14.9MB/s]\n",
      "Fetching 15 files:  27%|██▋       | 4/15 [00:41<02:35, 14.15s/it]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "pytorch_model.bin: 100%|██████████| 246M/246M [00:46<00:00, 5.34MB/s]\n",
      "Fetching 15 files:  47%|████▋     | 7/15 [00:46<00:54,  6.76s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "diffusion_pytorch_model.bin: 100%|██████████| 167M/167M [00:52<00:00, 3.17MB/s]\n",
      "diffusion_pytorch_model.bin: 100%|██████████| 1.72G/1.72G [01:50<00:00, 15.5MB/s]\n",
      "Fetching 15 files: 100%|██████████| 15/15 [01:51<00:00,  7.45s/it]\n",
      "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]c:\\Users\\Katie\\anaconda3\\envs\\ldm\\lib\\site-packages\\transformers\\models\\clip\\feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  3.21it/s]\n",
      "100%|██████████| 50/50 [00:12<00:00,  4.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch \n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16, revision=\"fp16\")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "image = pipe(prompt).images[0]\n",
    "    \n",
    "image.save(\"astronaut_rides_horse.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vae\\diffusion_pytorch_model.safetensors not found\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:04<00:00,  1.53it/s]\n",
      "100%|██████████| 50/50 [08:42<00:00, 10.44s/it]\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-inpainting\",\n",
    "    revision=\"fp16\",\n",
    "    torch_dtype=torch.float32,\n",
    ")\n",
    "prompt = \"transition between the red and blue cross sectional sections using green contours\"\n",
    "#image and mask_image should be PIL images.\n",
    "#The mask structure is white for inpainting and black for keeping as is\n",
    "\n",
    "from PIL import Image\n",
    "with Image.open(\"testimage3.png\") as im:\n",
    "    im.load()\n",
    "with Image.open(\"testimage3copy.png\") as mask:\n",
    "    mask.load()\n",
    "image = pipe(prompt=prompt, image=im, mask_image=mask).images[0]\n",
    "image.save(\"./imgonnacry.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prosthetics3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
